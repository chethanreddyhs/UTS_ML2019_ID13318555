{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chethanreddyhs/UTS_ML2019_ID13318555/blob/master/A1_13318555.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy0yEIUheJCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://github.com/chethanreddyhs/UTS_ML2019_ID13318555/tree/master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFFQImBheSgF",
        "colab_type": "text"
      },
      "source": [
        "#32513 - Machine Learning\n",
        "#Assignment 1: Understanding the Literature\n",
        "#Name : Chethan Halaganahalli Shankara Reddy\n",
        "#Student Number: 13318555\n",
        "#Review Report on “Generative Adversarial Nets”\n",
        "#Introduction\n",
        "This paper proposed by Ian Goodfellow, is the first paper to propose the Generative Adversarial Network (GAN) and it was the most prominent and revolutionary idea in the field of machine learning when it was published.\n",
        "\n",
        "Generative Adversarial Network is a framework that consists of two models that learn from each other to generate output. It has a Generator which generates the data and a Discriminator that finds out if the data has come from training data or from the generator. The generator must be trained such that it should generate the data to fool the discriminator.\n",
        "\n",
        "\n",
        "#Content.\n",
        "In Generative Adversarial Network we have 2 different agents playing a game against each other. One of the agents is generator network which tries to generate data and the other agent is a discriminator network which samples data and estimates whether it is real or fake.  In Generative Adversarial Networks both players in the game are neural networks and the goal is to learn to generate data that resembles the data that was in the training set. The aim of the generator is to fool the discriminator and as both players get better and better at their job over time eventually the generator is forced to create data that is as realistic as possible. Both networks can be trained using stochastic gradient descent with exact gradients computed by maximum likelihood. The reason that we call the training process generative adversarial training is because the worst case input for one of these networks is generated by the other player and so one of the players is always trained to do as well as possible on the worst possible input. \n",
        "\n",
        "The two players play a Min-Max game where the cost function for the generator is just the negative of the cost for the discriminator. So we can think of this as having a single value that the discriminator is trying to maximize and the generator is trying to minimize. The value that the two players are fighting over is the cross-entropy between the discriminators, predictions, the correct labels and the binary classification task of discriminating real data from fake data. So we have one term where we are feeding data and we are with a discriminator  which is trying to maximize the log probability of assigning one to the data and then we have another term where the discriminator is aiming to maximize the log probability of assigning 0 to the fake samples. When we look for an equilibrium point to a game it's different than minimizing a function.\n",
        "\n",
        "\n",
        "#Innovation\n",
        "There are other models that are similar to GANs like autoencoders, Deep belief networks and variational auto encoders to which this model is compared with and it surpasses the limitations of these models.\n",
        "\n",
        "Some of the limitations are if the optimizer is perfect and if we have infinite training data, we are not able to recover exactly the distribution that was used to generate the data. In practice we observe that variational autoencoders are very good at obtaining high likelihood, but they tend to produce lower quality samples and the samples are often relatively blurry. Another major family of models is the Bolton machine.  These also have an explicit density function that is not actually tractable. In this case the Bolton machine is defined by an energy function and the probability of a state is proportional the value of the energy. In order to convert this to an actual probability distribution it started to renormalize by dividing by the sum over all the different states and that sum becomes intractable. We're able to approximate it using Monte Carlo methods but those Monte Carlo methods often suffer from problems like failing to mix between different modes and in general Monte Carlo methods like Markov chain Monte Carlo method perform very poorly in high dimensional spaces because the Markov chains break down for very large images.\n",
        "  \n",
        "When there is a finite training data we can eventually recover the correct distribution. There are no need of Markov chains to train the generative adversarial Network or to draw samples from it and there is an important requirement based on the way that the Markov chains seem to hold back restricted Boltzmann machines. Now a days there are some models that use Markov chains more successfully. A major advantage of generative adversarial networks is that they are often regarded\n",
        "as producing the best samples compared to other models like variational autoencoders. \n",
        "\n",
        "#Technical Quality\n",
        "The technical quality of the paper is very high. Being the first paper to propose Generative Adversarial Nets, it was termed as the most interesting idea in the field of Machine Learning in the past decade by prominent people in the industry.\n",
        "The paper is supported with enough documentation to be deemed technical. The experiments conducted and the theories proposed are supported with relevant equations and codes. The paper takes into account the present models and explains how the Generative Adversarial Network model is better than the existing one. The authors also provided the link to the code on the Github which is helpful in accessing and verifying the experimental results.\n",
        "3 generative models are used for comparison and 2 tests are conducted. However, the results obtained are not very easy to understand and assimilate. Although it felt like the conclusions were drawn from few tests there were not many methods existing at the time to test as conclude.\n",
        "\n",
        "\n",
        "#Application and X-Factor\n",
        "\n",
        "The generative adversarial networks (GAN) are related to Machine Learning domain which play a similar role as that of the other generative models. In this model the generator has the ability to create new set of data from the existing one. A good GAN model can be so good at training data that if a data set of random images is fed to the generator, a whole new set of images can be obtained as output which is created by the model.\n",
        "The most infamous application of GAN is Deepfakes. This technology was used to create convincing images and videos of the celebrities and were uploaded on the internet. Some of the output were so real that the evolution of the technology suggests that the future outputs will be indistinguishable to the real ones. The GANs were used to create new paintings similar to that of the Pablo Picassa’s and the newly generated ones were strikingly similar to the real one which were sold for a whopping amount of money.\n",
        "The recent upgradation to the GANs was the Faceapp application that produces different facial features and old age faces which took the internet by storm. The technology has to be improved to limit its misuse in the field and research can be focussed on this.\n",
        "\n",
        "\n",
        "#Presentation: \n",
        "The overall quality of the paper was too high and purely technical. Beforehand knowledge of the subject is very essential to understand and assimilate the content of the paper. The introduction and the abstract were clear enough to get and idea of the quality of the content. The explanation of the concept was straightforward and did not have unnecessary content. Although the tests conducted were not handy enough, a little research in the field provided an understanding of the conclusions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUp-aOA8TPTT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}