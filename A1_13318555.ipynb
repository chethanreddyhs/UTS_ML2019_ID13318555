{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chethanreddyhs/UTS_ML2019_ID13318555/blob/master/A1_13318555.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy0yEIUheJCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://github.com/chethanreddyhs/UTS_ML2019_ID13318555/tree/master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFFQImBheSgF",
        "colab_type": "text"
      },
      "source": [
        "#Introduction\n",
        "This paper proposed by Ian Goodfellow, is the first paper to propose the Generative Adversarial Network (GAN) and it was the most prominent and revolutionary idea in the field of machine learning when it was published.\n",
        "\n",
        "#Content.\n",
        "Generative Adversarial Network is a framework that consists of two models that learn from each other to generate output. It has a Generator which generates the data and a Discriminator that finds out if the data has come training data or from the generator. The generator has to be trained such that it should generate the data to fool the discriminator. \n",
        "The main reason GANs derive its name is because the worst output to each neural network model\n",
        "Generative models attempt to map the actual distribution of the training data in order to create new data points. This is in contrast to discriminative models, which instead try to find a mapping from X to Y for the purpose of prediction. Generative Adversarial Networks are able to produce data points by learning data distribution through adversarial learning. This is where the generative model competes with a discriminative model which is trained to guess whether a given sample is from the actual data distribution or was artificially generated by the generative model. The goal of the generative model during training is to reduce the chance of the discriminative model making a correct prediction to be as close to 50% as possible, at which point the artificial data points are no different to the actual data points. \n",
        "Generative Adversarial Networks address many issues with the prevailing generative models of the time, the most notable issue being the intractability of some probability calculations which would then necessitate the use of less accurate approximations or Markov chains. This problem is avoided in Generative Adversarial Networks as no assumptions about the distribution of the data are made and the model instead learns through competition between the generative model and a discriminative model. If multi-layer perceptrons (MLPs) are used for both the generative and discriminative model, then the GAN will also have the advantage of being able to use many of the features of MLPs such as backpropagation (for training both the generative and discriminative model) and dropout (for preventing the discriminative model from overfitting).\n",
        "\n",
        "minimum, competitive with current state-of-the-art generative models, not to provide a comparison. \n",
        "\n",
        "\n",
        "#Innovation\n",
        "\n",
        "\n",
        "Notes to talk about: \n",
        "•\t• Not a niche field - generative models have a huge number of applications so any improvements could have a large impact. Deep fakes are evidence of GANs being more than just a gimmick/niche algorithm with limited applicability. \n",
        "•\t• The paper contributes to a new algorithm/technique for developing generative models. \n",
        "•\t• Able to overcome previous limitations of previous generative models. E.g. needing Markov chains for sampling, needing approximations for calculating actual distribution p(x) since it is intractable \n",
        "•\t• The technique can be applied to the same situations that previous generative models could be applied to. \n",
        "•\t• Will the model perform better in all situations? Can't exactly be gauged due to the limited number of tests. However, from the qualitative and quantitative analysis, GANs are promising \n",
        "•\t• The paper does provide the groundwork for future innovations in the field. With GANs being a new method (at the time of publishing), there is plenty of exploration that can be done with GANs. \n",
        "\n",
        "#Application and X-Factor\n",
        "\n",
        "The authors do not discuss the application domain of GANs. However, it can be assumed that the application domain is no different from that of other generative models. Generative models are primarily useful for any problem in which data points, rather than predictions, must be outputted from the model, with the 'data points' representing images. Already GANs have proven their usefulness when applied to this set of problems. A rather infamous application of GANs is Deep Fakes, where convincing videos of celebrities were created and uploaded online. The amount of media attention generated by Deep is testament to the suitability of GANs for generating images or sequences of images. Deep Fakes have not only brought to light the power of GANs but also highlighted the potential for GANs to be used maliciously. \n",
        "GANs could also potentially be used for more artistic purposes. Since GANs have the ability to generate images that are in some way similar to training images, new pieces of art could be created that is based on a particular artstyle or even a combination of artstyles. In fact, Yanghua Jin et al in their 2017 paper [reference here] were able to demonstrate the ability of GANs to create facial images of anime characters. These images could also be used to provide inspiration to an artist, especially in cases where the generated images may not be of high quality. \n",
        "There are multiple directions that future research can take in order to further develop GANs. Future works could conduct research from an optimization perspective, where the research is focused on achieving performance increases. The authors have suggested that efficiency can be increased through the development of better methods for training the generative and discriminative model as well as better methods for sampling from the distribution. Further research could also develop variants of GANs such as conditional GANs, which add an extra input to the generative model such as a class label. This would allow for the generative model to be able to generate data points from a specific class and would further expand the application domain of GANs. Finally, rather than focusing on producing better performing models, future research could focus on minimizing the impact of GANs when utilized for malicious purposes. With the open-source nature of tools for implementing GANs and with techniques for implementing GANs becoming more sophisticated and powerful, it is inevitable that there will be an increase in the misuse of GANs. Therefore, research should also look into ways of either preventing misuse or reducing the impact of any potential misuse. However once GANs become powerful enough, this research will most likely be rendered useless as the theoretical limit for GANs is when they have replicated the distribution of the actual data at which point artificially generated images are indistinguishable from the actual images. \n",
        "\n",
        "#Presentation: \n",
        "The presentation of the paper is of a high standard of quality. The introduction and abstract provide a clear overview of what the paper is about without bombarding the reader with too much detail. The body of the paper contains plenty of depth and does not waste time discussing irrelevant points. Appropriate formatting is used for mathematical equations and pseudocode, and diagrams and graphs are provided in order to present a clearer view of certain concepts. The language used throughout the paper avoids being overly verbose. The only area that was\n"
      ]
    }
  ]
}